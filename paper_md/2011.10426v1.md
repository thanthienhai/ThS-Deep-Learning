arXiv:2011.10426v1 [cs.CL] 20 Nov 2020

Fine-Tuning BERT for Sentiment Analysis of Vietnamese Reviews

Quoc Thai Nguyen*†, Thoai Linh Nguyen*†, Ngoc Hoang Luong*†, and Quoc Hung Ngo*†

*University of Information Technology, Ho Chi Minh City, Vietnam
†Vietnam National University, Ho Chi Minh City, Vietnam

**Abstract**—Sentiment analysis is an important task in the field of Nature Language Processing (NLP), in which users' feedback data on a specific issue are evaluated and analyzed. Many deep learning models have been proposed to tackle this task, including the recently-introduced Bidirectional Encoder Representations from Transformers (BERT) model. In this paper, we experiment with two BERT fine-tuning methods for the sentiment analysis task on datasets of Vietnamese reviews: 1) a method that uses only the [CLS] token as the input for an attached feed-forward neural network, and 2) another method in which all BERT output vectors are used as the input for classification. Experimental results on two datasets show that models using BERT slightly outperform other models using GloVe and FastText. Also, regarding the datasets employed in this study, our proposed BERT fine-tuning method produces a model with better performance than the original BERT fine-tuning method.

Keywords – sentiment analysis, BERT, pre-trained language model, deep learning.

# 1. Introduction

Nowadays, customers often leave their reviews about various kinds of products and services, which they have used on a wide range of online platforms, from shopping sites to social media. Such user experience information is a valuable source of reference for potential customers to make their buying decisions, and especially, for related companies to improve their businesses. However, it is prohibitively cumbersome to manually process such large amounts of data. Automated sentiment analysis systems are, therefore, essential to study customers' subjective opinions from their reviews in an efficient manner. A fundamental task of such systems is sentiment analysis, in which it is inferred from the contents of each review whether the reviewer likes or dislikes the thing being discussed about.

In 2018, Devlin et al. [5] introduces a new language representation model, namely BERT (Bidirectional Encoder Representations from Transformers). This model has successfully improved recent works in finding representations of words in a digital space from their context. In this paper, we will present two methods for the sentiment analysis of Vietnamese reviews, and both are based on the BERT language model. Firstly, we implement the classification method proposed in Jacob Devlin's study [5]. Secondly, we propose a new method for text classification that integrates

BERT into three classification models. We aim to exhibit the effectiveness of BERT for the sentiment analysis task compared to other models. We carry out other fine-tuning BERT methods for sentiment analysis and select the best model to combine with BERT.

The next section reviews related works for the sentiment analysis task. Section 3 gives an overview of Word Embedding, Language model and BERT model. Section 4 describes details of two methods for fine-tuning BERT on sentiment analysis. The experimental results and analysis with our classification approach are described in Section 5. Finally, we conclude the paper and give some future research directions in Section 6.

# 2. Related Work

Sentiment analysis is one of text classification tasks, in which the input text is classified as sentiment labels, such as “positive” or “negative” label. There are several studies on this task with machine learning approaches and lexicon/dictionary approaches (as shown in Table 1). In 2002, the first research to classify the reviews into two groups, positive and negative [3]. Several studies used supervised learning models to solve the task, such as, Support Vector Machine (SVM) [6], [7], Naïve Bayes [1], [14]. In another study, they use a dictionary of emotional vocabulary, which indicates whether a word is positive or negative along with it level [9].

Recently, deep learning approaches allow to learn better representations for words based on their context. Yoon Kim used Convolution Neural Network (CNN) [16] for the document classification task, the author process with each character-based. Mikolov et al. [19] proposed an unsupervised learning algorithm neural network called “Paragraph vector”, which is similar to the work in [21]. However, they not using bag-of-words of context words as input, but an additional matrix of text with each column of matrix is a “Paragraph vector”.

In Vietnamese text, Duyen et al. use Naïve Bayes, Max Entropy Model and SVM to classify reviews on the Agoda site [11], which allows users to book hotel rooms on travel occasions. The results show that the SVM model achieves the best result. Quan et al. [20] employs a deep learning approach, proposing a model that combines Long Short-Term Memory (LSTM) and CNN, namely multi-channel LSTM-CNN for Vietnamese sentiment analysis. The combined model achieves a performance better than both CNN and

---

LSTM alone. This approach is similar to [10], which a deep learning model is used for managing negative comments on social networks. Word vectors are passed through the CNN component, and the output is then used as the input for the LSTM network to perform classification.

TABLE 1. APPROACHES FOR SENTIMENT ANALYSIS

<table><thead><tr><th></th><th>Description</th><th>Author</th></tr></thead><tbody><tr><td><strong>English</strong></td><td></td><td></td></tr><tr><td>Lexicon-based</td><td>Dataset positive/negative</td><td>[9]</td></tr><tr><td>Naïve Bayes</td><td>Dataset positive/negative</td><td>[14] [1]</td></tr><tr><td>SVM</td><td>Dataset positive/negative</td><td>[6] [7]</td></tr><tr><td>TextCNN</td><td>This model is tested 8 Dataset</td><td>[16]</td></tr><tr><td><strong>Vietnamese</strong></td><td></td><td></td></tr><tr><td>Naïve Bayes</td><td>Positive/negative, 73.65% F1-score</td><td>[11]</td></tr><tr><td>MEM</td><td>Positive/negative, 82.6% F1-score</td><td>[11]</td></tr><tr><td>SVM</td><td>Positive/negative, 80.4% F1-score</td><td>[11]</td></tr><tr><td>CNN-LSTM</td><td>Positive/negative/neutral, 87.2%, 59.6 F1-score</td><td>[20]</td></tr><tr><td>CNN-LSTM</td><td>Positive/negative/neutral, 85.5%, 72% F1-score</td><td>[10]</td></tr></tbody></table>

In summary, deep learning is currently the state-of-the-art approach for the field for sentiment analysis. However, Vietnamese resources for NLP tasks are limited, while popular word representation models, such as Word2Vec or GloVe, are fixed and not contextually flexible. In this study, we experiment with fine-tuning BERT to address the sentiment analysis task for Vietnamese language.

## 3. Background

### 3.1. Word Embedding

Word Embedding is a method of mapping each word into a multi-dimensional real space, however its size is much smaller than the dictionary size. Several studies introduced approaches for the word embedding step in NLP tasks. Tomas Mikolos proposed Word2Vec [21], which is a statistical method for efficiently learning a standalone word embedding from a text corpus. The global Vectors for Word Representation (GloVe) algorithm is another method for efficiently learning word vectors, developed by Pennington et al. [8]. Unlike context-free techniques (e.g., GloVe, word2vec), Bidirectional Encoder Representation from Transformer (BERT) is a state-of-the-art language model that generates a contextual representation for each word, taking into account its neighboring words [5].

### 3.2. Language Model

The language model is a probability distribution over text sets. The language model can show how much probability a sentence (or phrase) belongs to a language. Language models analyze bodies of text data to provide a basis for their word predictions.

$$P(x_1...x_n)$$

where $x_1,x_2,...,x_n$ is the sequence of words that make up a sentence, and $n$ is length of the sentence ($n > 1$).

Currently, pre-trained language models are widely used in NLP tasks. These models have been trained on a very large dataset, integrating many languages and knowledge. Users can thus use them in many different NLP tasks [5].

### 3.3. BERT

BERT is a multi-layered structure of Bidirectional Transformer encoder layers, based on the architecture of transformer [2]. BERT uses Bidirectional Transformer encoders replace Encoders combining Decoders. BERT fine-tuning tasks do not require Decoder blocks. Therefore, they replace Decoder blocks with similar Encoder blocks.

The most advantage of BERT is to apply two-dimensional training techniques of Transformers from a very famous Attention model to a Language Model. Different from previous NLP studies, which look at a text string from left to right, BERT combines how to look at a text string from 2 dimensions (from left to right and right to left). This method can greatly improve the retention of Representations of words in sentences. The published results also show that the trained language model has a more profound contextual meaning than previous models.

Two sizes have been proposed for the BERT model:

* $BERT_{BASE}$: 12 encoder block, 12 head attention, 110 million parameters.
* $BERT_{LARGE}$: 24 encoder block, 16 head attention, 340 million parameters.

## 4. Methodology

For the sentiment analysis task of review texts, BERT can be used with two approaches:

* **Feature extraction:** This method uses BERT as a feature extraction model. The architecture of the BERT model is preserved, and its outputs are feature input vectors for subsequent classification models to solve the given problem.
* **Fine-tuning:** In this method, we need to modify the architecture of the model by adding some layers at the end of BERT model. These layers will solve the problem, and retrain the model. This process is called fine-tuning. In [5], this method is also the main method used to evaluate benchmarks on different tasks, showing BERT superiority over previous models.

TABLE 2. COMPARISON BETWEEN FINE-TUNING AND FEATURE-BASED APPROACHES WITH BERT [5]

<table><thead><tr><th>SYSTEM</th><th>Dev F1</th><th>Test F1</th></tr></thead><tbody><tr><td><strong>Fine-tuning approach</strong></td><td></td><td></td></tr><tr><td><em>BERT<sub>LARGE</sub></em></td><td>96.6</td><td>92.8</td></tr><tr><td><em>BERT<sub>BASE</sub></em></td><td>96.4</td><td>92.4</td></tr><tr><td><strong>Feature-based approach (<em>BERT<sub>BASE</sub></em>)</strong></td><td></td><td></td></tr><tr><td>Embeddings</td><td>91.0</td><td>-</td></tr><tr><td>Second-to-Last Hidden</td><td>95.6</td><td>-</td></tr><tr><td>Last Hidden</td><td>94.9</td><td>-</td></tr><tr><td>Weighted Sum Last Four Hidden</td><td>95.9</td><td>-</td></tr><tr><td>Concat Last Four Hidden</td><td>96.1</td><td>-</td></tr><tr><td>Weighted Sum All 12 Layers</td><td>95.5</td><td>-</td></tr></tbody></table>

Table 2 (extracted from [5]) shows the performance of feature-based and fine-tuning approaches with BERT on

---

the Named Entity Recognition task (CoNLL-2003 NER [4]). Fine-tuning approaches achieve better performance than feature-based approaches, where different combinations of hidden vectors are experimented with. Therefore, in this paper, we decide to use the fine-tuning approach with BERT for our sentiment analysis task of Vietnamese reviews.

To fine-tune BERT, we need to employ a pre-trained BERT model. It is required that the pre-trained model has been trained with Vietnamese datasets. In this work, we use the pre-trained BERT-Base Multilingual Cased¹ provided by Google because it supports multiple languages, including Vietnamese along with other languages (104 languages). This pre-trained model is thus suitable for Vietnamese. Two methods of fine-tuning BERT for sentiment analysis are as follows.

*   **Fine-tuning BERT using token [CLS]:** Devlin et al. [5] perform fine-tuning of BERT at the sequence level. They add a special token to perform the classification tasks. A token [CLS] is added to the beginning position of the sentences. The output vector of this token will be sent through the feed-forward neutral network to perform input sentence classification (as shown in Figure 1). This model is named *BERT-base*.
*   **Fine-tuning BERT using all tokens:** We use the entire output of BERT including the token [CLS]. These outputs form a $SEQ\_LEN \times h$ matrix, where $SEQ\_LEN$ is the maximum length of the input sequence, and $h$ is the length of hidden vectors. We can then use this output matrix as the input to other classification model which can be one of three models: LSTM, TextCNN, or RCNN (as shown in Figure 2).

Figure 1. BERT-base architecture

1. https://github.com/google-research/bert

Figure 2. BERT architecture using all tokens

**Long Short-Term Memory (LSTM):** We employ the Long Short-Term Memory (LSTM), which is the most widely-used recurrent neural network (RNN) model, that addresses the distance dependence issue of the classical RNN model. The LSTM layer then continues to extract the features received from BERT.

**Text Convolution Neural Network (TextCNN):** The convolution model in this research is TextCNN [18]. This is the CNN model widely used in nature language processing tasks, especially for classification tasks thanks to the quick training time and good results. The TextCNN model employed in this work is a little different from the TextCNN models suggested in [17], [18]. We use 4 regions sizes (2,3,4,5).

Figure 3. TextCNN architecture [17]

**Recurrent Convolutional Network (RCNN):** The model is a combination of recurrent and convolutional architectures [13]. Two LSTM architectures are combined: one earns the context of words from left to right while the other

---

learns contextually from right to left. The output of both networks is then passed through a *conv1d* layer to continue extracting. The RCNN architecture is described in Figure 4.

Figure 3, Figure 4 illustrate the architectures that will be associated with BERT in this work. To perform classification of *Positive* and *Negative* labels, we use the logistics function.

Based on the experimental results of [5], fine-tuning approaches give better performance than feature-based approaches (as shown in Table 2). Among the feature-based approaches, the one that concatenate the last four hidden outputs gives the best results. In this paper, we decide to also concatenate the last four hidden outputs when performing fine-tuning. Each hidden output has $dim = h$. Therefore, concatenating four hidden outputs results in the dimensions of the output vector having $dim = 4 \times h$.

## 5. Experiments & Discussions

### 5.1. Datasets

We employ two datasets to train and evaluate all the models that are investigated in this paper. The two datasets consist of reviewing texts commented by users on e-commerce sites.

First, the Ntc-sv² dataset includes reviews about food and restaurants on Foody. This dataset consists of 50,000 samples. The labels are assigned based on the average score (avg_score): the ones above 8.5 are labeled *positive*, the ones less than 5 are labeled *negative*.

Second, the *Vreview* dataset is built on the training dataset of a competition of AIVIVN³ on sentiment analysis, which consists users' comments of product reviews on various e-commerce sites. In addition, we include some comments about food and restaurants on *Foody*⁴. We then perform data labeling through the average score (avg_score) similarly to the Ntc-sv dataset. However, a slightly different thresholds are used here: the samples with average scores above 7.5 are labeled *positive*, and the ones below 5 are labeled *negative*.

Employing two datasets with different characteristics would help to better evaluate the performance of different models. Some data statistics are made for the evaluation process are showed in Tables 3 and 4. These are the statistics after the data have been processed.

TABLE 3. DATA DESCRIPTION AFTER PRE-PROCESS

<table><thead><tr><th rowspan="2">Dataset</th><th colspan="2">Train</th><th colspan="2">Test</th><th rowspan="2">Totally</th></tr><tr><th>Positive</th><th>Negative</th><th>Positive</th><th>Negative</th></tr></thead><tbody><tr><td>Ntc-sv</td><td>20,493</td><td>20,267</td><td>5,000</td><td>5,000</td><td>50,760</td></tr><tr><td>Vreview</td><td>22,979</td><td>19,537</td><td>8,301</td><td>6,795</td><td>57,612</td></tr></tbody></table>

2. https://streetcodevn.com/blog/sav
3. https://www.aivivn.com/contests/1
4. https://forum.machinelarningcoban.com/t/du-lieu-review-cua-foody/203

TABLE 4. STATISTICS OF WORDS INCLUDED IN THE COMMENTS

<table><thead><tr><th></th><th>Vreview</th><th>Ntc-sv</th></tr></thead><tbody><tr><th>Mean</th><td>55.45</td><td>86.57</td></tr><tr><th>Stdn</th><td>63.75</td><td>77.41</td></tr><tr><th>Min</th><td>1</td><td>1</td></tr><tr><th>25%</th><td>14</td><td>37</td></tr><tr><th>50%</th><td>32</td><td>65</td></tr><tr><th>75%</th><td>76</td><td>111</td></tr><tr><th>Max</th><td>435</td><td>1,501</td></tr></tbody></table>

### 5.2. Models

In this paper, we employ the following machine learning and deep learning models in comparison with the BERT models for the sentiment analysis task over our datasets of Vietnamese reviews.

* **SVM / Boosting**: SVM and Boosting are two classic machine learning algorithms. In this study, SVM experiments are based on *n*-grams features (*n* in the range [1,5]), while Boosting experiments are based on the XGBoosting algorithm [15] (deep = 15).
* **FastText + LSTM / TextCNN / RCNN**: We choose three deep learning architectures to combine with the word embedding model FastText ⁵, which was pre-trained on a Vietnamese dataset.
* **GloVE + LSTM / TextCNN / RCNN**: Because we do not have pre-trained GloVE embeddings with the same dimensions as the pre-trained FastText embedding, we use the glove-python⁶ library to train the word embedding model. Models associated with GloVE would then be similar to models combined with FastText, ensuring fair comparisons in our experiments.

### 5.3. Results & Discussions

The performance results of all the competing models on the two datasets are shown in Tables 5 and 6.

TABLE 5. EXPERIMENTAL RESULTS ON NTC-SV DATASET

<table><thead><tr><th>Model</th><th>Precision(%)</th><th>Recall(%)</th><th>F1(%)</th></tr></thead><tbody><tr><td>SVM</td><td>89.23</td><td>92.52</td><td>90.84</td></tr><tr><td>XGBoost</td><td>88.76</td><td>90.58</td><td>89.63</td></tr><tr><td>FastText + TextCNN</td><td>67.9</td><td>89.1</td><td>77.1</td></tr><tr><td>FastText + LSTM</td><td>88.5</td><td>89.7</td><td>89.1</td></tr><tr><td>FastText + RCNN</td><td>89.2</td><td>91.7</td><td>90.4</td></tr><tr><td>Glove + TextCNN</td><td>69.7</td><td>87.7</td><td>77.7</td></tr><tr><td>Glove + LSTM</td><td>88.7</td><td>91.8</td><td>89.8</td></tr><tr><td>Glove + RCNN</td><td>85.8</td><td>85.8</td><td>90.7</td></tr><tr><td>BERT-base</td><td>88.13</td><td><strong>94.02</strong></td><td>90.9</td></tr><tr><td>BERT-LSTM</td><td><strong>89.78</strong></td><td>92.08</td><td>90.91</td></tr><tr><td>BERT-TextCNN</td><td>88.85</td><td>93.14</td><td>90.94</td></tr><tr><td>BERT-RCNN</td><td>88.76</td><td>93.68</td><td><strong>91.15</strong></td></tr></tbody></table>

The following conclusions can be drawn from the experiments with BERT-based approaches and other approaches:

5. https://fasttext.cc/docs/en/crawl-vectors.html
6. https://github.com/maciejkula/glove-python

---

Figure 4. RCNN Architecture

TABLE 6. EXPERIMENTAL RESULTS ON VREVIEW DATASET

<table><thead><tr><th>Model</th><th>Precision(%)</th><th>Recall(%)</th><th>F1(%)</th></tr></thead><tbody><tr><td>SVM</td><td>86.26</td><td>86.9</td><td>86.5</td></tr><tr><td>XGBoost</td><td>87.69</td><td>88.45</td><td>88.07</td></tr><tr><td>FastText + TextCNN</td><td>61.8</td><td><b>94</b></td><td>74.6</td></tr><tr><td>FastText + LSTM</td><td>88.5</td><td>86.4</td><td>87.5</td></tr><tr><td>FastText + RCNN</td><td>84.5</td><td>89.8</td><td>87.1</td></tr><tr><td>Glove + TextCNN</td><td>62.6</td><td>93</td><td>74.8</td></tr><tr><td>Glove + LSTM</td><td>85.8</td><td>85.8</td><td>85.8</td></tr><tr><td>Glove + RCNN</td><td>84.0</td><td>88.6</td><td>86.2</td></tr><tr><td>BERT-base</td><td>86.08</td><td>88.44</td><td>87.2</td></tr><tr><td>BERT-LSTM</td><td>85.25</td><td>89.9</td><td>87.5</td></tr><tr><td>BERT-TextCNN</td><td><b>90.9</b></td><td>85.2</td><td>87.98</td></tr><tr><td>BERT-RCNN</td><td>87.08</td><td>89.38</td><td><b>88.22</b></td></tr></tbody></table>

* When comparing the models on the ntc-sv dataset, it can be seen that the results are not considerably different, even when comparing BERT models with SVM. Therefore, deep learning models are not much superior in this case. The training time of BERT-based approaches is much longer than the training time of the SVM approach; however, their performances are not much better than SVM's.

* Models using the word embeddings FastText and GloVe produce similar results. First, TextCNN models produce very poor results, much lower than other models. Secondly, the models using architectures of LSTM and RCNN, especially models using RCNN architecture produce very good results, because it combines the features that are received from many sources, from which there is more information available for better classifying the reviews. Their training times, however, are considerably longer.

* The BERT-based, BERT-LSTM, and BERT-TextCNN approaches similarly exhibit good performance on both datasets.

* BERT-RCNN is the model that gives the best results among the models considered in this paper. It can be seen that RCNN is not only suitable when combined with BERT but also effective in combination with other embedding methods. The experimental results here suggest that RCNN is the most suitable approach to be combined with BERT to implement fine-tuning.

The experimental results did not show a considerable difference between BERT and other models, although we used a different fine-tuning approach, which made the most of the information from BERT. These results can be explained with the following reasons:

* The lengths of the comments are relatively short and the pre-processing procedure eliminates most of the potential confusions, making it easier to classify the comments.

* All the fine-tuning BERT approaches, BERT-base and BERT in combination with other deep learning architecture, require a lot of computational resources, namely RAM and GPU. The input string for BERT after sub-splitting is 512, but our resources are not enough to be able to fine-tune BERT with the input string length of 512. If we had enough resources to process the maximum input length, the performance of BERT-based methods could be further improved.

* Pre-trained BERT-Base Multilingual Cased might still be sub-optimal for Vietnamese language. The sub-word separator in BERT uses the sub-word separation technique for English, which might lead to inaccurate separations when being applied to Vietnamese. The pre-trained BERT model, therefore, has certain contextual deviations for Vietnamese words.

The source code, models and datasets of this study can be downloaded at: https://github.com/thoailinh/Sentiment-Analysis-using-BERT.

## 6. Conclusion

We have fine-tuned BERT using the pre-trained multilingual BERT with two approaches and both exhibit better performance compared to other machine learning and deep learning models considered in this paper. When performing fine-tuning BERT, the entire output of BERT can be employed, providing the subsequent classification model with more useful information. The experimental results showed that fine-tuning BERT with LSTM or TextCNN yielded no considerable improvement compared to the BERT-base fine-tuning approach. Instead, BERT could be integrated with

---

models using RCNN or other architectures that combine
recurrent and convolutional models.

The experimental results show that the BERT-RCNN
model using our proposed fine-tuning method yields cer-
tain improvement of the accuracy performance for senti-
ment analysis on datasets containing Vietnamese reviews.
Although the improvement is not considerably superior,
it exhibits potentials for further enhancements. For future
work, we aim to extend the proposed method for aspect-
based sentiment analysis, and more extensive experiments
could be conducted on different datasets.

References

[1] Lopamudra Dey Sanjay Chakraborty et al., “Sentiment Analysis of Review Datasets Using Naïve Bayes and K-NN Classifier”, in International Journal of Information Engineering and Electronic Business, 2016.
[2] Ashish Vaswani et al. “Attention is all you need”, 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.
[3] Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan, “Sentiment classification using machine learning techniques”, in Proceedings of Conference on Empirical Methods in Natural Language Processing (EMNLP-2002), 2002.
[4] Erik F Tjong Kim Sang and Fien De Meulder, “Introduction to the conll-2003 shared task: Language-independent named entity recognition”. In CoNLL (2003).
[5] Jacob Devlin, et al. “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding”. 2018.
[6] Bhumika M. Jadav and Vimalkumar B. Vaghela, “Sentiment Analysis using Support Vector Machine based on Feature Selection and Semantic Analysis”, in International Journal of Computer Applications 2016.
[7] Nurulhuda Zainuddin and Ali Selamat, “Sentiment analysis using Support Vector Machine”, 2014 International Conference on Computer, Communications, and Control Technology (I4CT).
[8] Jeffrey Pennington, Richard Socher, Christopher Manning, “GloVe: Global Vectors for Word Representation”, in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 2014.

[9] Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede, “Lexicon-Based Methods for Sentiment Analysis”, Computational Linguistics, vol. 37, no. 2, pp. 267-307, 2011.
[10] Khuong Vo, Tri Nguyen, Dang Pham, Mao Nguyen, Minh Truong, Dinh Nguyen, Tho Quan, “Handling negative mentions on social media channels using deep learning”, Journal of Information and Telecommunication, vol. 3, no. 3, 2019.
[11] Nguyen Thi Duyen, Ngo Xuan Bach, Tu Minh Phuong, “An Empirical Study on Sentiment Analysis for Vietnamese”. The 2014 International Conference on Advanced Technologies for Communications (ATC’14).
[12] Peter D. Turney, “Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews”, in Proceedings of Annual Meeting of the Association for Computational Linguistics (ACL-2002), 2002.
[13] Siuwei Lai, Liheng Xu, Kang Liu, Jun Zhao, “Recurrent Convolutional Neural Networks for Text Classification”, Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (2015).
[14] Kavya Suppala, Narasinga Rao, “Sentiment Analysis Using Naïve Bayes Classifier”, in International Journal of Innovative Technology and Exploring Engineering (IJITEE) 2019
[15] Tianqi Chen, Carlos Guestrin, “XGBoost: A Scalable Tree Boosting System”, The 22nd ACM SIGKDD International Conference (2016).
[16] Xiang Zhang, Junbo Zhao, Yann LeCun, “Character-level Convolutional Networks for Text Classification”, arXiv:1509.01626, 2015.
[17] Ye Zhang, Byron C. Wallace, “A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification”, IJCNLP 2017.
[18] Yoon Kim “Convolution Neutral Network for Sententce Classification”, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).
[19] Quoc Le, Tomas Mikolov, “Distributed Representations of Sentences and Documents”, in Proceedings of the International Conference on Machine Learning (ICML 2014), 2014.
[20] Quan-Hoang Vo, Huy-Tien Nguyen, Bac Le, Minh-Le Nguyen, “Multi-channel LSTM-CNN model for Vietnamese sentiment analysis”, 2017 9th International Conference on Knowledge and Systems Engineering (KSE).
[21] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Jeffrey Dean, “Distributed Representations of Words and Phrases and their Compositionality”, in Proceedings of the 26th International Conference on Neural Information Processing Systems (NIPS 2013), 2013.